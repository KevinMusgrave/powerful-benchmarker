


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.5.0">
    
    
      
        <title>A Metric Learning Reality Check - Powerful Benchmarker</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.b5d04df8.min.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/palette.9ab2c1f8.min.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="black" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#a-metric-learning-reality-check" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="Powerful Benchmarker" class="md-header-nav__button md-logo" aria-label="Powerful Benchmarker">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Powerful Benchmarker
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              A Metric Learning Reality Check
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/KevinMusgrave/powerful-benchmarker/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    KevinMusgrave/powerful-benchmarker
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Powerful Benchmarker" class="md-nav__button md-logo" aria-label="Powerful Benchmarker">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Powerful Benchmarker
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/KevinMusgrave/powerful-benchmarker/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    KevinMusgrave/powerful-benchmarker
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../cl_syntax/" title="Command Line Syntax" class="md-nav__link">
      Command Line Syntax
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../yaml_syntax/" title="Yaml Syntax" class="md-nav__link">
      Yaml Syntax
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../hyperparams/" title="Hyperparameter Optimization" class="md-nav__link">
      Hyperparameter Optimization
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../modules/" title="Modules Available By Default" class="md-nav__link">
      Modules Available By Default
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../custom/" title="Adding Custom Modules" class="md-nav__link">
      Adding Custom Modules
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      Default Config File Guide
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Default Config File Guide" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Default Config File Guide
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_dataset/" title="config_dataset" class="md-nav__link">
      config_dataset
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_eval/" title="config_eval" class="md-nav__link">
      config_eval
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_factories/" title="config_factories" class="md-nav__link">
      config_factories
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_general/" title="config_general" class="md-nav__link">
      config_general
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_loss_and_miners/" title="config_loss_and_miners" class="md-nav__link">
      config_loss_and_miners
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_models/" title="config_models" class="md-nav__link">
      config_models
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_optimizers/" title="config_optimizers" class="md-nav__link">
      config_optimizers
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../configs/config_transforms/" title="config_transforms" class="md-nav__link">
      config_transforms
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-8" type="checkbox" id="nav-8">
    
    <label class="md-nav__link" for="nav-8">
      Code Documentation
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Code Documentation" data-md-level="1">
      <label class="md-nav__title" for="nav-8">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Code Documentation
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/aggregators/" title="Aggregators" class="md-nav__link">
      Aggregators
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/api_parsers/" title="API Parsers" class="md-nav__link">
      API Parsers
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/architectures/" title="Architectures" class="md-nav__link">
      Architectures
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/datasets/" title="Datasets" class="md-nav__link">
      Datasets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/ensembles/" title="Ensembles" class="md-nav__link">
      Ensembles
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/factories/" title="Factories" class="md-nav__link">
      Factories
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/runners/" title="Runners" class="md-nav__link">
      Runners
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/split_managers/" title="Split Managers" class="md-nav__link">
      Split Managers
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../code/utils/" title="Utils" class="md-nav__link">
      Utils
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-9" type="checkbox" id="nav-9" checked>
    
    <label class="md-nav__link" for="nav-9">
      Papers
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Papers" data-md-level="1">
      <label class="md-nav__title" for="nav-9">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Papers
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        A Metric Learning Reality Check
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg>
        </span>
      </label>
    
    <a href="./" title="A Metric Learning Reality Check" class="md-nav__link md-nav__link--active">
      A Metric Learning Reality Check
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#optimization-plots" class="md-nav__link">
    Optimization plots
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimal-hyperparameters" class="md-nav__link">
    Optimal hyperparameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples-of-unfair-comparisons-in-metric-learning-papers" class="md-nav__link">
    Examples of unfair comparisons in metric learning papers
  </a>
  
    <nav class="md-nav" aria-label="Examples of unfair comparisons in metric learning papers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#papers-that-use-a-better-architecture-than-their-competitors-but-dont-disclose-it" class="md-nav__link">
    Papers that use a better architecture than their competitors, but don’t disclose it
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-use-a-higher-dimensionality-than-their-competitors-but-dont-disclose-it" class="md-nav__link">
    Papers that use a higher dimensionality than their competitors, but don’t disclose it
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-claim-to-do-a-simple-256-resize-and-227-or-224-random-crop-but-actually-use-the-more-advanced-randomresizedcrop-method" class="md-nav__link">
    Papers that claim to do a simple 256 resize and 227 or 224 random crop, but actually use the more advanced RandomResizedCrop method
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-use-a-256-crop-size-but-whose-competitor-results-use-a-smaller-227-or-224-size" class="md-nav__link">
    Papers that use a 256 crop size, but whose competitor results use a smaller 227 or 224 size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-omit-details" class="md-nav__link">
    Papers that omit details
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples-to-back-up-other-claims-in-section-21" class="md-nav__link">
    Examples to back up other claims in section 2.1
  </a>
  
    <nav class="md-nav" aria-label="Examples to back up other claims in section 2.1">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#most-papers-claim-to-apply-the-following-transformations-resize-the-image-to-256-x-256-randomly-crop-to-227-x-227-and-do-a-horizontal-flip-with-50-chance-the-following-papers-support-this-claim" class="md-nav__link">
    “Most papers claim to apply the following transformations: resize the image to 256 x 256, randomly crop to 227 x 227, and do a horizontal flip with 50% chance”. The following papers support this claim
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-categorized-by-the-optimizer-they-use" class="md-nav__link">
    Papers categorized by the optimizer they use
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-do-not-use-confidence-intervals" class="md-nav__link">
    Papers that do not use confidence intervals
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-do-not-use-a-validation-set" class="md-nav__link">
    Papers that do not use a validation set
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-papers-report-for-the-contrastive-and-triplet-losses" class="md-nav__link">
    What papers report for the contrastive and triplet losses
  </a>
  
    <nav class="md-nav" aria-label="What papers report for the contrastive and triplet losses">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#reported-precision1-for-the-contrastive-loss" class="md-nav__link">
    Reported Precision@1 for the Contrastive Loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reported-precision1-for-the-triplet-loss" class="md-nav__link">
    Reported Precision@1 for the Triplet Loss
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#frequently-asked-questions" class="md-nav__link">
    Frequently Asked Questions
  </a>
  
    <nav class="md-nav" aria-label="Frequently Asked Questions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#do-you-have-slides-that-accompany-the-paper" class="md-nav__link">
    Do you have slides that accompany the paper?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isnt-it-unfair-to-fix-the-model-optimizer-learning-rate-and-embedding-size" class="md-nav__link">
    Isn't it unfair to fix the model, optimizer, learning rate, and embedding size?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-did-you-use-bn-inception" class="md-nav__link">
    Why did you use BN-Inception?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-was-the-batch-size-set-to-32-for-most-of-the-results" class="md-nav__link">
    Why was the batch size set to 32 for most of the results?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-werent-more-hard-mining-methods-evaluated" class="md-nav__link">
    Why weren't more hard-mining methods evaluated?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-the-contrastive-loss-why-is-the-optimal-positive-margin-a-negative-value" class="md-nav__link">
    For the contrastive loss, why is the optimal positive margin a negative value?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#in-figure-2-papers-vs-reality-why-do-you-use-precision1-instead-of-mapr" class="md-nav__link">
    In Figure 2 (papers vs reality) why do you use Precision@1 instead of MAP@R?
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reproducing-results" class="md-nav__link">
    Reproducing results
  </a>
  
    <nav class="md-nav" aria-label="Reproducing results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#download-the-experiment-folder" class="md-nav__link">
    Download the experiment folder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#command-line-scripts" class="md-nav__link">
    Command line scripts
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-evaluation-on-the-test-set" class="md-nav__link">
    Run evaluation on the test set
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#optimization-plots" class="md-nav__link">
    Optimization plots
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimal-hyperparameters" class="md-nav__link">
    Optimal hyperparameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples-of-unfair-comparisons-in-metric-learning-papers" class="md-nav__link">
    Examples of unfair comparisons in metric learning papers
  </a>
  
    <nav class="md-nav" aria-label="Examples of unfair comparisons in metric learning papers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#papers-that-use-a-better-architecture-than-their-competitors-but-dont-disclose-it" class="md-nav__link">
    Papers that use a better architecture than their competitors, but don’t disclose it
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-use-a-higher-dimensionality-than-their-competitors-but-dont-disclose-it" class="md-nav__link">
    Papers that use a higher dimensionality than their competitors, but don’t disclose it
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-claim-to-do-a-simple-256-resize-and-227-or-224-random-crop-but-actually-use-the-more-advanced-randomresizedcrop-method" class="md-nav__link">
    Papers that claim to do a simple 256 resize and 227 or 224 random crop, but actually use the more advanced RandomResizedCrop method
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-use-a-256-crop-size-but-whose-competitor-results-use-a-smaller-227-or-224-size" class="md-nav__link">
    Papers that use a 256 crop size, but whose competitor results use a smaller 227 or 224 size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-omit-details" class="md-nav__link">
    Papers that omit details
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples-to-back-up-other-claims-in-section-21" class="md-nav__link">
    Examples to back up other claims in section 2.1
  </a>
  
    <nav class="md-nav" aria-label="Examples to back up other claims in section 2.1">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#most-papers-claim-to-apply-the-following-transformations-resize-the-image-to-256-x-256-randomly-crop-to-227-x-227-and-do-a-horizontal-flip-with-50-chance-the-following-papers-support-this-claim" class="md-nav__link">
    “Most papers claim to apply the following transformations: resize the image to 256 x 256, randomly crop to 227 x 227, and do a horizontal flip with 50% chance”. The following papers support this claim
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-categorized-by-the-optimizer-they-use" class="md-nav__link">
    Papers categorized by the optimizer they use
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-do-not-use-confidence-intervals" class="md-nav__link">
    Papers that do not use confidence intervals
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#papers-that-do-not-use-a-validation-set" class="md-nav__link">
    Papers that do not use a validation set
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-papers-report-for-the-contrastive-and-triplet-losses" class="md-nav__link">
    What papers report for the contrastive and triplet losses
  </a>
  
    <nav class="md-nav" aria-label="What papers report for the contrastive and triplet losses">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#reported-precision1-for-the-contrastive-loss" class="md-nav__link">
    Reported Precision@1 for the Contrastive Loss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reported-precision1-for-the-triplet-loss" class="md-nav__link">
    Reported Precision@1 for the Triplet Loss
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#frequently-asked-questions" class="md-nav__link">
    Frequently Asked Questions
  </a>
  
    <nav class="md-nav" aria-label="Frequently Asked Questions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#do-you-have-slides-that-accompany-the-paper" class="md-nav__link">
    Do you have slides that accompany the paper?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#isnt-it-unfair-to-fix-the-model-optimizer-learning-rate-and-embedding-size" class="md-nav__link">
    Isn't it unfair to fix the model, optimizer, learning rate, and embedding size?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-did-you-use-bn-inception" class="md-nav__link">
    Why did you use BN-Inception?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-was-the-batch-size-set-to-32-for-most-of-the-results" class="md-nav__link">
    Why was the batch size set to 32 for most of the results?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-werent-more-hard-mining-methods-evaluated" class="md-nav__link">
    Why weren't more hard-mining methods evaluated?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#for-the-contrastive-loss-why-is-the-optimal-positive-margin-a-negative-value" class="md-nav__link">
    For the contrastive loss, why is the optimal positive margin a negative value?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#in-figure-2-papers-vs-reality-why-do-you-use-precision1-instead-of-mapr" class="md-nav__link">
    In Figure 2 (papers vs reality) why do you use Precision@1 instead of MAP@R?
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reproducing-results" class="md-nav__link">
    Reproducing results
  </a>
  
    <nav class="md-nav" aria-label="Reproducing results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#download-the-experiment-folder" class="md-nav__link">
    Download the experiment folder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#command-line-scripts" class="md-nav__link">
    Command line scripts
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-evaluation-on-the-test-set" class="md-nav__link">
    Run evaluation on the test set
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/KevinMusgrave/powerful-benchmarker/edit/master/docs/papers/mlrc.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  
                
                
                <h1 id="a-metric-learning-reality-check">A Metric Learning Reality Check<a class="headerlink" href="#a-metric-learning-reality-check" title="Permanent link">&para;</a></h1>
<p>This page contains additional information for the <a href="https://arxiv.org/abs/2003.08505">ECCV 2020 paper</a> by Musgrave et al.</p>
<h2 id="optimization-plots">Optimization plots<a class="headerlink" href="#optimization-plots" title="Permanent link">&para;</a></h2>
<p>Click on the links below to view the bayesian optimization plots. These are also available in the <a href="https://docs.google.com/spreadsheets/d/1brUBishNxmld-KLDAJewIc43A4EVZk3gY6yKe8OIKbY/">benchmark spreadsheet</a>.</p>
<p>The plots were generated using the <a href="https://github.com/facebook/Ax" target="_blank">Ax</a> package.</p>
<table>
<thead>
<tr>
<th>CUB200</th>
<th>Cars196</th>
<th>SOP</th>
<th>CUB200 with Batch 256</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="../mlrc_plots/cub_contrastive.html" target="_blank">Contrastive</a></td>
<td><a href="../mlrc_plots/cars_contrastive.html" target="_blank">Contrastive</a></td>
<td><a href="../mlrc_plots/sop_contrastive.html" target="_blank">Contrastive</a></td>
<td><a href="../mlrc_plots/cub_contrastive_large_batch.html" target="_blank">Contrastive</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_triplet.html" target="_blank">Triplet</a></td>
<td><a href="../mlrc_plots/cars_triplet.html" target="_blank">Triplet</a></td>
<td><a href="../mlrc_plots/sop_triplet.html" target="_blank">Triplet</a></td>
<td><a href="../mlrc_plots/cub_triplet_large_batch.html" target="_blank">Triplet</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_ntxent.html" target="_blank">NTXent</a></td>
<td><a href="../mlrc_plots/cars_ntxent.html" target="_blank">NTXent</a></td>
<td><a href="../mlrc_plots/sop_ntxent.html" target="_blank">NTXent</a></td>
<td><a href="../mlrc_plots/cub_ntxent_large_batch.html" target="_blank">NTXent</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_proxy_nca.html" target="_blank">ProxyNCA</a></td>
<td><a href="../mlrc_plots/cars_proxy_nca.html" target="_blank">ProxyNCA</a></td>
<td><a href="../mlrc_plots/sop_proxy_nca.html" target="_blank">ProxyNCA</a></td>
<td><a href="../mlrc_plots/cub_proxy_nca_large_batch.html" target="_blank">ProxyNCA</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_margin_no_weight_decay.html" target="_blank">Margin</a></td>
<td><a href="../mlrc_plots/cars_margin_no_weight_decay.html" target="_blank">Margin</a></td>
<td><a href="../mlrc_plots/sop_margin_no_weight_decay.html" target="_blank">Margin</a></td>
<td><a href="../mlrc_plots/cub_margin_large_batch_no_weight_decay.html" target="_blank">Margin</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_margin_param_per_class_no_weight_decay.html" target="_blank">Margin / class</a></td>
<td><a href="../mlrc_plots/cars_margin_param_per_class_no_weight_decay.html" target="_blank">Margin / class</a></td>
<td><a href="../mlrc_plots/sop_margin_param_per_class_no_weight_decay.html" target="_blank">Margin / class</a></td>
<td><a href="../mlrc_plots/cub_margin_param_per_class_large_batch_no_weight_decay.html" target="_blank">Margin / class</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_normalized_softmax.html" target="_blank">Normalized Softmax</a></td>
<td><a href="../mlrc_plots/cars_normalized_softmax.html" target="_blank">Normalized Softmax</a></td>
<td><a href="../mlrc_plots/sop_normalized_softmax.html" target="_blank">Normalized Softmax</a></td>
<td><a href="../mlrc_plots/cub_normalized_softmax_large_batch.html" target="_blank">Normalized Softmax</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_cosface.html" target="_blank">CosFace</a></td>
<td><a href="../mlrc_plots/cars_cosface.html" target="_blank">CosFace</a></td>
<td><a href="../mlrc_plots/sop_cosface.html" target="_blank">CosFace</a></td>
<td><a href="../mlrc_plots/cub_cosface_large_batch.html" target="_blank">CosFace</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_arcface.html" target="_blank">ArcFace</a></td>
<td><a href="../mlrc_plots/cars_arcface.html" target="_blank">ArcFace</a></td>
<td><a href="../mlrc_plots/sop_arcface.html" target="_blank">ArcFace</a></td>
<td><a href="../mlrc_plots/cub_arcface_large_batch.html" target="_blank">ArcFace</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_fast_ap.png" target="_blank">FastAP</a></td>
<td><a href="../mlrc_plots/cars_fast_ap.png" target="_blank">FastAP</a></td>
<td><a href="../mlrc_plots/sop_fast_ap.png" target="_blank">FastAP</a></td>
<td><a href="../mlrc_plots/cub_fastap_large_batch.html" target="_blank">FastAP</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_snr_contrastive.html" target="_blank">SNR Contrastive</a></td>
<td><a href="../mlrc_plots/cars_snr_contrastive.html" target="_blank">SNR Contrastive</a></td>
<td><a href="../mlrc_plots/sop_snr_contrastive.html" target="_blank">SNR Contrastive</a></td>
<td><a href="../mlrc_plots/cub_snr_contrastive_large_batch.html" target="_blank">SNR Contrastive</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_multi_similarity.html" target="_blank">Multi Similarity</a></td>
<td><a href="../mlrc_plots/cars_multi_similarity.html" target="_blank">Multi Similarity</a></td>
<td><a href="../mlrc_plots/sop_multi_similarity.html" target="_blank">Multi Similarity</a></td>
<td><a href="../mlrc_plots/cub_multi_similarity_large_batch.html" target="_blank">Multi Similarity</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_multi_similarity_with_ms_miner.html" target="_blank">Multi Similarity + Miner</a></td>
<td><a href="../mlrc_plots/cars_multi_similarity_with_ms_miner.html" target="_blank">Multi Similarity + Miner</a></td>
<td><a href="../mlrc_plots/sop_multi_similarity_with_ms_miner.html" target="_blank">Multi Similarity + Miner</a></td>
<td><a href="../mlrc_plots/cub_multi_similarity_with_ms_miner_large_batch_wider_range.html" target="_blank">Multi Similarity + Miner</a></td>
</tr>
<tr>
<td><a href="../mlrc_plots/cub_soft_triple.html" target="_blank">SoftTriple</a></td>
<td><a href="../mlrc_plots/cars_soft_triple.html" target="_blank">SoftTriple</a></td>
<td><a href="../mlrc_plots/sop_soft_triple.html" target="_blank">SoftTriple</a></td>
<td><a href="../mlrc_plots/cub_soft_triple_large_batch_wider_range.html" target="_blank">SoftTriple</a></td>
</tr>
</tbody>
</table>
<h2 id="optimal-hyperparameters">Optimal hyperparameters<a class="headerlink" href="#optimal-hyperparameters" title="Permanent link">&para;</a></h2>
<p>The values below are also available in the <a href="https://docs.google.com/spreadsheets/d/1brUBishNxmld-KLDAJewIc43A4EVZk3gY6yKe8OIKbY/">benchmark spreadsheet</a>.</p>
<table>
<thead>
<tr>
<th>Loss function</th>
<th>CUB200</th>
<th>Cars196</th>
<th>SOP</th>
<th>CUB200 with Batch 256</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Contrastive</strong><br/>pos_margin<br/>neg_margin</td>
<td><br/>-0.2000<br/>0.3841</td>
<td><br/>0.2652<br/>0.5409</td>
<td><br/>0.2850<br/>0.5130</td>
<td><br/>0.2227<br/>0.7694</td>
</tr>
<tr>
<td><strong>Triplet</strong><br/>margin</td>
<td><br/>0.0961</td>
<td><br/>0.1190</td>
<td><br/>0.0451</td>
<td><br/>0.1368</td>
</tr>
<tr>
<td><strong>NTXent</strong><br/>temperature</td>
<td><br/>0.0091</td>
<td><br/>0.0219</td>
<td><br/>0.0002</td>
<td><br/>0.0415</td>
</tr>
<tr>
<td><strong>ProxyNCA</strong><br/>proxy lr<br/>softmax_scale</td>
<td><br/>6.04e-3<br/>13.98</td>
<td><br/>4.43e-3<br/>7.97</td>
<td><br/>5.28e-4<br/>10.73</td>
<td><br/>2.16e-1<br/>10.03</td>
</tr>
<tr>
<td><strong>Margin</strong><br/>beta lr<br/>margin<br/>init beta</td>
<td><br/>1.31e-3<br/>0.0878<br/>0.7838<br/></td>
<td><br/>1.11e-4<br/>0.0781<br/>1.3164<br/></td>
<td><br/>1.82e-3<br/>0.0915<br/>1.1072</td>
<td><br/>1.00e-6<br/>0.0674<br/>0.9762</td>
</tr>
<tr>
<td><strong>Margin / class</strong><br/>beta lr<br/>margin<br/>init beta</td>
<td><br/>2.65e-4<br/>0.0779<br/>0.9796</td>
<td><br/>4.76e-05<br/>0.0776<br/>0.9598</td>
<td><br/>7.10e-05<br/>0.0518<br/>0.8424</td>
<td><br/>1.32e-2<br/>-0.0204<br/>0.1097</td>
</tr>
<tr>
<td><strong>Normalized Softmax</strong><br/>weights lr<br/>temperature</td>
<td><br/>4.46e-3<br/>0.1087</td>
<td><br/>1.10e-2<br/>0.0886</td>
<td><br/>5.46e-4<br/>0.0630</td>
<td><br/>7.20e-2<br/>0.0707</td>
</tr>
<tr>
<td><strong>CosFace</strong><br/>weights lr<br/>margin<br/>scale<br/></td>
<td><br/>2.53e-3<br/>0.6182<br/>100.0</td>
<td><br/>7.41e-3<br/>0.4324<br/>161.5</td>
<td><br/>2.16e-3<br/>0.3364<br/>100.0</td>
<td><br/>3.99e-3<br/>0.4144<br/>88.23</td>
</tr>
<tr>
<td><strong>ArcFace</strong><br/>weights lr<br/>margin<br/>scale<br/></td>
<td><br/>5.13e-3<br/>23.22<br/>100.0</td>
<td><br/>7.39e-06<br/>20.52<br/>49.50</td>
<td><br/>2.01e-3<br/>18.63<br/>220.3</td>
<td><br/>3.95e-2<br/>23.14<br/>78.86</td>
</tr>
<tr>
<td><strong>FastAP</strong><br/>num_bins</td>
<td><br/>17</td>
<td><br/>27</td>
<td><br/>16</td>
<td><br/>86</td>
</tr>
<tr>
<td><strong>SNR Contrastive</strong><br/>pos_margin<br/>neg_margin<br/>regularizer_weight</td>
<td><br/>0.3264<br/>0.8446<br/>0.1382</td>
<td><br/>0.1670<br/>0.9337<br/>0</td>
<td><br/>0.3759<br/>1.0831<br/>0</td>
<td><br/>0.1182<br/>0.6822<br/>0.4744</td>
</tr>
<tr>
<td><strong>Multi Similarity</strong><br/>alpha<br/>beta<br/>base</td>
<td><br/>0.01<br/>50.60<br/>0.56</td>
<td><br/>14.35<br/>75.83<br/>0.66</td>
<td><br/>8.49<br/>57.38<br/>0.41</td>
<td><br/>0.01<br/>46.85<br/>0.82</td>
</tr>
<tr>
<td><strong>Multi Similarity + Miner</strong><br/>alpha<br/>beta<br/>base<br/>epsilon</td>
<td><br/>17.97<br/>75.66<br/>0.77<br/>0.39</td>
<td><br/>7.49<br/>47.99<br/>0.63<br/>0.72</td>
<td><br/>15.94<br/>156.61<br/>0.72<br/>0.34</td>
<td><br/>11.63<br/>55.20<br/>0.85<br/>0.42</td>
</tr>
<tr>
<td><strong>SoftTriple</strong><br/>weights lr<br/>la<br/>gamma<br/>reg_weight<br/>margin</td>
<td><br/>5.37e-05<br/>78.02<br/>58.95<br/>0.3754<br/>0.4307</td>
<td><br/>1.40e-4<br/>17.69<br/>19.18<br/>0.0669<br/>0.3588</td>
<td><br/>8.68e-05<br/>100.00<br/>47.90<br/>N/A<br/>0.3145</td>
<td><br/>1.06e-4<br/>72.12<br/>51.07<br/>0.4430<br/>0.6959</td>
</tr>
</tbody>
</table>
<h2 id="examples-of-unfair-comparisons-in-metric-learning-papers">Examples of unfair comparisons in metric learning papers<a class="headerlink" href="#examples-of-unfair-comparisons-in-metric-learning-papers" title="Permanent link">&para;</a></h2>
<h4 id="papers-that-use-a-better-architecture-than-their-competitors-but-dont-disclose-it">Papers that use a better architecture than their competitors, but don’t disclose it<a class="headerlink" href="#papers-that-use-a-better-architecture-than-their-competitors-but-dont-disclose-it" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Wu_Sampling_Matters_in_ICCV_2017_paper.pdf">Sampling Matters in Deep Embedding Learning (ICCV 2017)</a></p>
<ul>
<li>Uses ResNet50, but all competitors use GoogleNet</li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Ge_Deep_Metric_Learning_ECCV_2018_paper.pdf">Deep Metric Learning with Hierarchical Triplet Loss (ECCV 2018)</a></p>
<ul>
<li>Uses BN-Inception, but all competitors use GoogleNet</li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning (CVPR 2019)</a></p>
<ul>
<li>Uses BN-Inception. Claims better performance than ensemble methods, but the ensemble methods use GoogleNet.</li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Cakir_Deep_Metric_Learning_to_Rank_CVPR_2019_paper.pdf">Deep Metric Learning to Rank (CVPR 2019)</a></p>
<ul>
<li>Uses ResNet50. In their SOP table, only 1 out of 11 competitor methods use ResNet50. All others use BN-Inception or GoogleNet. Claims better performance than ensemble methods, but the ensemble methods use GoogleNet. </li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Sanakoyeu_Divide_and_Conquer_the_Embedding_Space_for_Metric_Learning_CVPR_2019_paper.pdf">Divide and Conquer the Embedding Space for Metric Learning (CVPR 2019)</a></p>
<ul>
<li>Uses ResNet50. In their Cars196 and SOP tables, only 1 out of 15 competitor methods use ResNet50. The rest use GoogleNet or BN-Inception. The same is true for their CUB200 results, but in that table, they re-implement two of the competitors to use ResNet50.</li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Qian_SoftTriple_Loss_Deep_Metric_Learning_Without_Triplet_Sampling_ICCV_2019_paper.pdf">SoftTriple Loss: Deep Metric Learning Without Triplet Sampling (ICCV 2019)</a></p>
<ul>
<li>Uses BN-Inception. Compares with N-pairs and HDC, but doesn’t mention that these use GoogleNet. They only mention the competitors’ architectures when the competitors use an equal or superior network. Specifically, they mention that the Margin loss uses ResNet50, and HTL uses BN-Inception.</li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Deep_Metric_Learning_With_Tuplet_Margin_Loss_ICCV_2019_paper.pdf">Deep Metric Learning with Tuplet Margin Loss (ICCV 2019)</a></p>
<ul>
<li>Uses ResNet50. In their SOP table, only 1 out of 10 competitors use ResNet50, and in their CUB200 and Cars196 tables, only 1 out of 8 competitors use ResNet50. The rest use GoogleNet or BN-Inception. They also claim better performance than ensemble methods, but the ensemble methods use GoogleNet.</li>
</ul>
</li>
</ul>
<h4 id="papers-that-use-a-higher-dimensionality-than-their-competitors-but-dont-disclose-it">Papers that use a higher dimensionality than their competitors, but don’t disclose it<a class="headerlink" href="#papers-that-use-a-higher-dimensionality-than-their-competitors-but-dont-disclose-it" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Wu_Sampling_Matters_in_ICCV_2017_paper.pdf">Sampling Matters in Deep Embedding Learning (ICCV 2017)</a></p>
<ul>
<li>Uses size 128. CUB200 table: 4 out of 7 use size 64. Cars196: 4 out of 5 use size 64. SOP: 4 out of 7 use size 64.</li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Ge_Deep_Metric_Learning_ECCV_2018_paper.pdf">Deep Metric Learning with Hierarchical Triplet Loss (ECCV 2018)</a></p>
<ul>
<li>Uses size 512. The top two non-ensemble competitor results use size 384 and 64.</li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Ranked_List_Loss_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Ranked List Loss for Deep Metric Learning (CVPR 2019)</a></p>
<ul>
<li>Uses size 512 or 1536. For all 3 datasets, 5 out of the 6 competitor results use size 64.</li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Deep_Metric_Learning_With_Tuplet_Margin_Loss_ICCV_2019_paper.pdf">Deep Metric Learning with Tuplet Margin Loss (ICCV 2019)</a></p>
<ul>
<li>Uses size 512. The only competing method that uses the same architecture, uses size 128.</li>
</ul>
</li>
</ul>
<h4 id="papers-that-claim-to-do-a-simple-256-resize-and-227-or-224-random-crop-but-actually-use-the-more-advanced-randomresizedcrop-method">Papers that claim to do a simple 256 resize and 227 or 224 random crop, but actually use the more advanced RandomResizedCrop method<a class="headerlink" href="#papers-that-claim-to-do-a-simple-256-resize-and-227-or-224-random-crop-but-actually-use-the-more-advanced-randomresizedcrop-method" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning (CVPR 2019)</a></p>
<ul>
<li><a href="https://github.com/MalongTech/research-ms-loss/blob/master/ret_benchmark/data/transforms/build.py#L17" target="_blank">Link to line in code</a></li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Sanakoyeu_Divide_and_Conquer_the_Embedding_Space_for_Metric_Learning_CVPR_2019_paper.pdf">Divide and Conquer the Embedding Space for Metric Learning (CVPR 2019)</a></p>
<ul>
<li><a href="https://github.com/CompVis/metric-learning-divide-and-conquer/blob/master/lib/data/set/transform.py#L51" target="_blank">Link to line in code</a></li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Roth_MIC_Mining_Interclass_Characteristics_for_Improved_Metric_Learning_ICCV_2019_paper.pdf">MIC: Mining Interclass Characteristics for Improved Metric Learning (ICCV 2019)</a></p>
<ul>
<li><a href="https://github.com/Confusezius/ICCV2019_MIC/blob/master/datasets.py#L324" target="_blank">Link to line in code</a></li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Qian_SoftTriple_Loss_Deep_Metric_Learning_Without_Triplet_Sampling_ICCV_2019_paper.pdf">SoftTriple Loss: Deep Metric Learning Without Triplet Sampling (ICCV 2019)</a></p>
<ul>
<li><a href="https://github.com/idstcv/SoftTriple/blob/master/train.py#L99" target="_blank">Link to line in code</a></li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Kim_Proxy_Anchor_Loss_for_Deep_Metric_Learning_CVPR_2020_paper.pdf">Proxy Anchor Loss for Deep Metric Learning (CVPR 2020)</a></p>
<ul>
<li><a href="https://github.com/tjddus9597/Proxy-Anchor-CVPR2020/blob/master/code/dataset/utils.py#L76" target="_blank">Link to line in code</a></li>
</ul>
</li>
</ul>
<h4 id="papers-that-use-a-256-crop-size-but-whose-competitor-results-use-a-smaller-227-or-224-size">Papers that use a 256 crop size, but whose competitor results use a smaller 227 or 224 size<a class="headerlink" href="#papers-that-use-a-256-crop-size-but-whose-competitor-results-use-a-smaller-227-or-224-size" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Jacob_Metric_Learning_With_HORDE_High-Order_Regularizer_for_Deep_Embeddings_ICCV_2019_paper.pdf">Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings (ICCV 2019)</a></p>
<ul>
<li>Although they do reimplement some algorithms, and the reimplementations presumably use a crop size of 256, they also compare to paper results that use 227 or 224.</li>
</ul>
</li>
</ul>
<h4 id="papers-that-omit-details">Papers that omit details<a class="headerlink" href="#papers-that-omit-details" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning (CVPR 2019)</a></p>
<ul>
<li><a href="https://github.com/MalongTech/research-ms-loss/blob/master/ret_benchmark/utils/freeze_bn.py" target="_blank">Freezes batchnorm parameters in their code</a>, but this is not mentioned in the paper.</li>
</ul>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Kim_Proxy_Anchor_Loss_for_Deep_Metric_Learning_CVPR_2020_paper.pdf">Proxy Anchor Loss for Deep Metric Learning (CVPR 2020)</a></p>
<ul>
<li>Uses the <a href="https://github.com/tjddus9597/Proxy-Anchor-CVPR2020/issues/1" target="_blank">sum of Global Average Pooling (GAP) and Global Max Pooling (GMP)</a>. Competitor papers use just GAP. This is not mentioned in the paper. </li>
</ul>
</li>
</ul>
<h2 id="examples-to-back-up-other-claims-in-section-21">Examples to back up other claims in section 2.1<a class="headerlink" href="#examples-to-back-up-other-claims-in-section-21" title="Permanent link">&para;</a></h2>
<h4 id="most-papers-claim-to-apply-the-following-transformations-resize-the-image-to-256-x-256-randomly-crop-to-227-x-227-and-do-a-horizontal-flip-with-50-chance-the-following-papers-support-this-claim">“Most papers claim to apply the following transformations: resize the image to 256 x 256, randomly crop to 227 x 227, and do a horizontal flip with 50% chance”. The following papers support this claim<a class="headerlink" href="#most-papers-claim-to-apply-the-following-transformations-resize-the-image-to-256-x-256-randomly-crop-to-227-x-227-and-do-a-horizontal-flip-with-50-chance-the-following-papers-support-this-claim" title="Permanent link">&para;</a></h4>
<ul>
<li><a href="https://arxiv.org/pdf/1511.06452.pdf">Deep Metric Learning via Lifted Structured Feature Embedding (CVPR 2016)</a></li>
<li><a href="https://www.cs.toronto.edu/~urtasun/publications/law_etal_icml17.pdf">Deep Spectral Clustering Learning (ICML 2017)</a></li>
<li><a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Song_Deep_Metric_Learning_CVPR_2017_paper.pdf">Deep Metric Learning via Facility Location (CVPR 2017)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Movshovitz-Attias_No_Fuss_Distance_ICCV_2017_paper.pdf">No Fuss Distance Metric Learning using Proxies (ICCV 2017)</a></li>
<li><a href="https://arxiv.org/pdf/1708.01682.pdf">Deep Metric Learning with Angular Loss (ICCV 2017)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Wu_Sampling_Matters_in_ICCV_2017_paper.pdf">Sampling Matters in Deep Embedding Learning (ICCV 2017)</a></li>
<li><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Duan_Deep_Adversarial_Metric_CVPR_2018_paper.pdf">Deep Adversarial Metric Learning (CVPR 2018)</a></li>
<li><a href="https://labs.pinterest.com/user/themes/pin_labs/assets/paper/classification-strong-baseline-bmvc-2019.pdf">Classification is a Strong Baseline for Deep Metric Learning (BMVC 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Hardness-Aware_Deep_Metric_Learning_CVPR_2019_paper.pdf">Hardness-Aware Deep Metric Learning (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Deep_Asymmetric_Metric_Learning_via_Rich_Relationship_Mining_CVPR_2019_paper.pdf">Deep Asymmetric Metric Learning via Rich Relationship Mining (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Suh_Stochastic_Class-Based_Hard_Example_Mining_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Stochastic Class-based Hard Example Mining for Deep Metric Learning (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Ranked_List_Loss_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Ranked List Loss for Deep Metric Learning (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Cakir_Deep_Metric_Learning_to_Rank_CVPR_2019_paper.pdf">Deep Metric Learning to Rank (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Sanakoyeu_Divide_and_Conquer_the_Embedding_Space_for_Metric_Learning_CVPR_2019_paper.pdf">Divide and Conquer the Embedding Space for Metric Learning (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Roth_MIC_Mining_Interclass_Characteristics_for_Improved_Metric_Learning_ICCV_2019_paper.pdf">MIC: Mining Interclass Characteristics for Improved Metric Learning (ICCV 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Qian_SoftTriple_Loss_Deep_Metric_Learning_Without_Triplet_Sampling_ICCV_2019_paper.pdf">SoftTriple Loss: Deep Metric Learning Without Triplet Sampling (ICCV 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Kim_Proxy_Anchor_Loss_for_Deep_Metric_Learning_CVPR_2020_paper.pdf">Proxy Anchor Loss for Deep Metric Learning (CVPR 2020)</a></li>
</ul>
<h4 id="papers-categorized-by-the-optimizer-they-use">Papers categorized by the optimizer they use<a class="headerlink" href="#papers-categorized-by-the-optimizer-they-use" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>SGD:</p>
<ul>
<li><a href="https://www.cs.toronto.edu/~urtasun/publications/law_etal_icml17.pdf">Deep Spectral Clustering Learning (ICML 2017)</a></li>
<li><a href="https://arxiv.org/pdf/1708.01682.pdf">Deep Metric Learning with Angular Loss (ICCV 2017)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Hard-Aware_Deeply_Cascaded_ICCV_2017_paper.pdf">Hard-Aware Deeply Cascaded Embedding (ICCV 2017)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Ge_Deep_Metric_Learning_ECCV_2018_paper.pdf">Deep Metric Learning with Hierarchical Triplet Loss (ECCV 2018)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Deep_Asymmetric_Metric_Learning_via_Rich_Relationship_Mining_CVPR_2019_paper.pdf">Deep Asymmetric Metric Learning via Rich Relationship Mining (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Ranked_List_Loss_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Ranked List Loss for Deep Metric Learning (CVPR 2019)</a></li>
<li><a href="https://labs.pinterest.com/user/themes/pin_labs/assets/paper/classification-strong-baseline-bmvc-2019.pdf">Classification is a Strong Baseline for Deep Metric Learning (BMVC 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Deep_Metric_Learning_With_Tuplet_Margin_Loss_ICCV_2019_paper.pdf">Deep Metric Learning with Tuplet Margin Loss (ICCV 2019)</a></li>
</ul>
</li>
<li>
<p>RMSprop:</p>
<ul>
<li><a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Song_Deep_Metric_Learning_CVPR_2017_paper.pdf">Deep Metric Learning via Facility Location (CVPR 2017)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Movshovitz-Attias_No_Fuss_Distance_ICCV_2017_paper.pdf">No Fuss Distance Metric Learning using Proxies (ICCV 2017)</a></li>
</ul>
</li>
<li>
<p>Adam:</p>
<ul>
<li><a href="https://papers.nips.cc/paper/6200-improved-deep-metric-learning-with-multi-class-n-pair-loss-objective.pdf">Improved Deep Metric Learning with Multi-class N-pair Loss Objective (Neurips 2016)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Wu_Sampling_Matters_in_ICCV_2017_paper.pdf">Sampling Matters in Deep Embedding Learning (ICCV 2017)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Hybrid-Attention_Based_Decoupled_Metric_Learning_for_Zero-Shot_Image_Retrieval_CVPR_2019_paper.pdf">Hybrid-Attention based Decoupled Metric Learning for Zero-Shot Image Retrieval (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Suh_Stochastic_Class-Based_Hard_Example_Mining_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Stochastic Class-based Hard Example Mining for Deep Metric Learning (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Cakir_Deep_Metric_Learning_to_Rank_CVPR_2019_paper.pdf">Deep Metric Learning to Rank (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Sanakoyeu_Divide_and_Conquer_the_Embedding_Space_for_Metric_Learning_CVPR_2019_paper.pdf">Divide and Conquer the Embedding Space for Metric Learning (CVPR 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Qian_SoftTriple_Loss_Deep_Metric_Learning_Without_Triplet_Sampling_ICCV_2019_paper.pdf">SoftTriple Loss: Deep Metric Learning Without Triplet Sampling (ICCV 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Jacob_Metric_Learning_With_HORDE_High-Order_Regularizer_for_Deep_Embeddings_ICCV_2019_paper.pdf">Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings (ICCV 2019)</a></li>
<li><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Roth_MIC_Mining_Interclass_Characteristics_for_Improved_Metric_Learning_ICCV_2019_paper.pdf">MIC: Mining Interclass Characteristics for Improved Metric Learning (ICCV 2019)</a></li>
</ul>
</li>
<li>
<p>AdamW</p>
<ul>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Kim_Proxy_Anchor_Loss_for_Deep_Metric_Learning_CVPR_2020_paper.pdf">Proxy Anchor Loss for Deep Metric Learning (CVPR 2020)</a></li>
</ul>
</li>
</ul>
<h4 id="papers-that-do-not-use-confidence-intervals">Papers that do not use confidence intervals<a class="headerlink" href="#papers-that-do-not-use-confidence-intervals" title="Permanent link">&para;</a></h4>
<ul>
<li>All of the previously mentioned papers</li>
</ul>
<h4 id="papers-that-do-not-use-a-validation-set">Papers that do not use a validation set<a class="headerlink" href="#papers-that-do-not-use-a-validation-set" title="Permanent link">&para;</a></h4>
<ul>
<li>All of the previously mentioned papers</li>
</ul>
<h2 id="what-papers-report-for-the-contrastive-and-triplet-losses">What papers report for the contrastive and triplet losses<a class="headerlink" href="#what-papers-report-for-the-contrastive-and-triplet-losses" title="Permanent link">&para;</a></h2>
<p>The tables below are what papers have reported for the contrastive and triplet loss, <strong>using convnets</strong>. We know that the papers are reporting convnet results because they explicitly say so. For example:</p>
<ul>
<li><a href="https://arxiv.org/pdf/1511.06452.pdf">Lifted Structure Loss</a>: See figures 6, 7, and 12, which indicate that the contrastive and triplet results were obtained using GoogleNet. These results have been cited several times in recent papers.</li>
<li><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Duan_Deep_Adversarial_Metric_CVPR_2018_paper.pdf">Deep Adversarial Metric Learning</a>: See tables 1, 2, and 3, and this quote from the bottom of page 6 / top of page 7: "For all the baseline methods and DAML, we employed the same GoogLeNet architecture pre-trained on ImageNet for fair comparisons"</li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Hardness-Aware_Deep_Metric_Learning_CVPR_2019_paper.pdf">Hardness-Aware Deep Metric Learning</a>: See tables 1, 2, and 3, and this quote from page 8: "We evaluated all the methods mentioned above using the same pretrained CNN model for fair comparison."</li>
</ul>
<h4 id="reported-precision1-for-the-contrastive-loss">Reported Precision@1 for the Contrastive Loss<a class="headerlink" href="#reported-precision1-for-the-contrastive-loss" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Paper</th>
<th>CUB200</th>
<th>Cars196</th>
<th>SOP</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://arxiv.org/pdf/1511.06452.pdf">Deep Metric Learning via Lifted Structured Feature Embedding (CVPR 2016)</a></td>
<td>26.4</td>
<td>21.7</td>
<td>42</td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/1611.00822.pdf">Learning Deep Embeddings with Histogram Loss (NIPS 2016)</a></td>
<td>26.4</td>
<td>N/A</td>
<td>42</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Hard-Aware_Deeply_Cascaded_ICCV_2017_paper.pdf">Hard-Aware Deeply Cascaded Embedding (ICCV 2017)</a></td>
<td>26.4</td>
<td>21.7</td>
<td>42</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Wu_Sampling_Matters_in_ICCV_2017_paper.pdf">Sampling Matters in Deep Embedding Learning (ICCV 2017)</a></td>
<td>N/A</td>
<td>N/A</td>
<td>30.1</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Duan_Deep_Adversarial_Metric_CVPR_2018_paper.pdf">Deep Adversarial Metric Learning (CVPR 2018)</a></td>
<td>27.2</td>
<td>27.6</td>
<td>37.5</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Wonsik_Kim_Attention-based_Ensemble_for_ECCV_2018_paper.pdf">Attention-based Ensemble for Deep Metric Learning (ECCV 2018)</a></td>
<td>26.4</td>
<td>21.7</td>
<td>42</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Hardness-Aware_Deep_Metric_Learning_CVPR_2019_paper.pdf">Deep Variational Metric Learning (ECCV 2018)</a></td>
<td>32.8</td>
<td>35.8</td>
<td>37.4</td>
</tr>
<tr>
<td><a href="https://labs.pinterest.com/user/themes/pin_labs/assets/paper/classification-strong-baseline-bmvc-2019.pdf">Classification is a Strong Baseline for Deep Metric Learning (BMVC 2019)</a></td>
<td>26.4</td>
<td>21.7</td>
<td>42</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Deep_Asymmetric_Metric_Learning_via_Rich_Relationship_Mining_CVPR_2019_paper.pdf">Deep Asymmetric Metric Learning via Rich Relationship Mining (CVPR 2019)</a></td>
<td>27.2</td>
<td>27.6</td>
<td>37.5</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Hardness-Aware_Deep_Metric_Learning_CVPR_2019_paper.pdf">Hardness-Aware Deep Metric Learning (CVPR 2019)</a></td>
<td>27.2</td>
<td>27.6</td>
<td>37.5</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Jacob_Metric_Learning_With_HORDE_High-Order_Regularizer_for_Deep_Embeddings_ICCV_2019_paper.pdf">Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings (ICCV 2019)</a></td>
<td>55</td>
<td>72.2</td>
<td>N/A</td>
</tr>
</tbody>
</table>
<h4 id="reported-precision1-for-the-triplet-loss">Reported Precision@1 for the Triplet Loss<a class="headerlink" href="#reported-precision1-for-the-triplet-loss" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Paper</th>
<th>CUB200</th>
<th>Cars196</th>
<th>SOP</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://arxiv.org/pdf/1511.06452.pdf">Deep Metric Learning via Lifted Structured Feature Embedding (CVPR 2016)</a></td>
<td>36.1</td>
<td>39.1</td>
<td>42.1</td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/1611.00822.pdf">Learning Deep Embeddings with Histogram Loss (NIPS 2016)</a></td>
<td>36.1</td>
<td>N/A</td>
<td>42.1</td>
</tr>
<tr>
<td><a href="https://papers.nips.cc/paper/6200-improved-deep-metric-learning-with-multi-class-n-pair-loss-objective.pdf">Improved Deep Metric Learning with Multi-class N-pair Loss Objective (NIPS 2016)</a></td>
<td>43.3</td>
<td>53.84</td>
<td>53.32</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Hard-Aware_Deeply_Cascaded_ICCV_2017_paper.pdf">Hard-Aware Deeply Cascaded Embedding (ICCV 2017)</a></td>
<td>36.1</td>
<td>39.1</td>
<td>42.1</td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/1708.01682.pdf">Deep Metric Learning with Angular Loss (ICCV 2017)</a></td>
<td>42.2</td>
<td>45.5</td>
<td>56.5</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Duan_Deep_Adversarial_Metric_CVPR_2018_paper.pdf">Deep Adversarial Metric Learning (CVPR 2018)</a></td>
<td>35.9</td>
<td>45.1</td>
<td>53.9</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Hardness-Aware_Deep_Metric_Learning_CVPR_2019_paper.pdf">Deep Variational Metric Learning (ECCV 2018)</a></td>
<td>39.8</td>
<td>58.5</td>
<td>54.9</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Ge_Deep_Metric_Learning_ECCV_2018_paper.pdf">Deep Metric Learning with Hierarchical Triplet Loss (ECCV 2018)</a></td>
<td>55.9</td>
<td>79.2</td>
<td>72.6</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Hardness-Aware_Deep_Metric_Learning_CVPR_2019_paper.pdf">Hardness-Aware Deep Metric Learning (CVPR 2019)</a></td>
<td>35.9</td>
<td>45.1</td>
<td>53.9</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Deep_Asymmetric_Metric_Learning_via_Rich_Relationship_Mining_CVPR_2019_paper.pdf">Deep Asymmetric Metric Learning via Rich Relationship Mining (CVPR 2019)</a></td>
<td>35.9</td>
<td>45.1</td>
<td>53.9</td>
</tr>
<tr>
<td><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Jacob_Metric_Learning_With_HORDE_High-Order_Regularizer_for_Deep_Embeddings_ICCV_2019_paper.pdf">Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings (ICCV 2019)</a></td>
<td>50.5</td>
<td>65.2</td>
<td>N/A</td>
</tr>
</tbody>
</table>
<h2 id="frequently-asked-questions">Frequently Asked Questions<a class="headerlink" href="#frequently-asked-questions" title="Permanent link">&para;</a></h2>
<h4 id="do-you-have-slides-that-accompany-the-paper">Do you have slides that accompany the paper?<a class="headerlink" href="#do-you-have-slides-that-accompany-the-paper" title="Permanent link">&para;</a></h4>
<p>Slides are <a href="https://docs.google.com/presentation/d/1KnLDFzMKLYlnMzMDc7wyKHVAh5dJ9z6Fs1qto4OqQFY/edit?usp=sharing" target="_blank">here</a>.</p>
<h4 id="isnt-it-unfair-to-fix-the-model-optimizer-learning-rate-and-embedding-size">Isn't it unfair to fix the model, optimizer, learning rate, and embedding size?<a class="headerlink" href="#isnt-it-unfair-to-fix-the-model-optimizer-learning-rate-and-embedding-size" title="Permanent link">&para;</a></h4>
<p>Our goal was to compare algorithms fairly. To accomplish this, we used the same network, optimizer, learning rate, image transforms, and embedding dimensionality for each algorithm. There is no theoretical reason why changing any of these parameters would benefit one particular algorithm over the rest. If there is no theoretical reason, then we can only speculate, and if we add hyperparameters based on speculation, then the search space becomes too large to explore.</p>
<h4 id="why-did-you-use-bn-inception">Why did you use BN-Inception?<a class="headerlink" href="#why-did-you-use-bn-inception" title="Permanent link">&para;</a></h4>
<p>We chose this architecture because it is commonly used in recent metric learning papers.</p>
<h4 id="why-was-the-batch-size-set-to-32-for-most-of-the-results">Why was the batch size set to 32 for most of the results?<a class="headerlink" href="#why-was-the-batch-size-set-to-32-for-most-of-the-results" title="Permanent link">&para;</a></h4>
<p>This was done for the sake of computational efficiency. Note that there are: </p>
<ul>
<li>3 datasets </li>
<li>14 algorithms </li>
<li>50 steps of bayesian optmization </li>
<li>4 fold cross validation </li>
</ul>
<p>This comes to 8400 models to train, which can take a considerable amount of time. Thus, a batch size of 32 made sense. It's also important to remember that there are real-world cases where a large batch size cannot be used. For example, if you want to train on large images, rather than the contrived case of 227x227, then training with a batch size of 32 suddenly makes a lot more sense because you are constrained by GPU memory. So it's reasonable to check the performance of these losses on a batch size of 32. </p>
<p>That said, there is a good theoretical reason for a larger batch size benefiting embedding losses more than classification losses. Specifically, embedding losses can benefit from the increased number of pairs/triplets in larger batches. To address this, we benchmarked the 14 methods on CUB200, using a batch size of 256. The results can be found in the supplementary section (the final page) of the paper.</p>
<h4 id="why-werent-more-hard-mining-methods-evaluated">Why weren't more hard-mining methods evaluated?<a class="headerlink" href="#why-werent-more-hard-mining-methods-evaluated" title="Permanent link">&para;</a></h4>
<p>We did test one loss+miner combination (Multi-similarity loss + their mining method). But we mainly wanted to do a thorough evaluation of loss functions, because that is the subject of most recent metric learning papers.   </p>
<h4 id="for-the-contrastive-loss-why-is-the-optimal-positive-margin-a-negative-value">For the contrastive loss, why is the optimal positive margin a negative value?<a class="headerlink" href="#for-the-contrastive-loss-why-is-the-optimal-positive-margin-a-negative-value" title="Permanent link">&para;</a></h4>
<p>A negative value should be equivalent to a margin of 0, because the distance between positive pairs cannot be negative, and the margin does not contribute to the gradient. So allowing the hyperparameter optimization to explore negative margins was unnecesary, but by the time I realized this, it wasn't worth changing the optimization bounds.</p>
<h4 id="in-figure-2-papers-vs-reality-why-do-you-use-precision1-instead-of-mapr">In Figure 2 (papers vs reality) why do you use Precision@1 instead of MAP@R?<a class="headerlink" href="#in-figure-2-papers-vs-reality-why-do-you-use-precision1-instead-of-mapr" title="Permanent link">&para;</a></h4>
<p>None of the referenced papers report MAP@R. Since Figure 2a is meant to show reported results, we had to use a metric that was actually reported, i.e. Precision@1. We used the same metric for Figure 2b so that the two graphs could be compared directly side by side. But for the sake of completeness, here's Figure 2b using MAP@R:</p>
<p><img alt="reality_over_time_mapr" src="../mlrc_plots/reality_over_time_mapr.png" /></p>
<h2 id="reproducing-results">Reproducing results<a class="headerlink" href="#reproducing-results" title="Permanent link">&para;</a></h2>
<h3 id="download-the-experiment-folder">Download the experiment folder<a class="headerlink" href="#download-the-experiment-folder" title="Permanent link">&para;</a></h3>
<ol>
<li>Download <a href="../..#getting-started">run.py and set the default flags</a></li>
<li>Go to the <a href="https://docs.google.com/spreadsheets/d/1brUBishNxmld-KLDAJewIc43A4EVZk3gY6yKe8OIKbY/">benchmark spreadsheet</a></li>
<li>Find the experiment you want to reproduce, and click on the link in the "Config files" column.</li>
<li>You'll see 3 folders: one for CUB, one for Cars, and one for SOP. Open the folder for the dataset you want to train on.</li>
<li>Now you'll see several files and folders, one of which ends in "reproduction0". Download this folder. (It will include saved models. If you don't want to download the saved models, go into the folder and download just the "configs" folder.)</li>
</ol>
<h3 id="command-line-scripts">Command line scripts<a class="headerlink" href="#command-line-scripts" title="Permanent link">&para;</a></h3>
<p>Normally reproducing results is as easy as downloading an experiment folder, and <a href="../..#reproduce-an-experiment">using the <code>reproduce_results</code> flag</a>. However, there have been significant changes to the API since these experiments were run, so there are a couple of extra steps required, and they depend on the dataset. </p>
<p>Additionally, if you are reproducing an experiment for the <strong>Contrastive, Triplet, or SNR Contrastive losses</strong>, you have to delete the key/value pair called <code>avg_non_zero_only</code> in the <code>config_loss_and_miners.yaml</code> file. And for the <strong>Contrastive loss</strong>, you should delete the <code>use_similarity</code> key/value pair in <code>config_loss_and_miners.yaml</code>. </p>
<p>In the following code, <code>&lt;experiment_to_reproduce&gt;</code> refers to the folder that <strong>contains</strong> the <code>configs</code> folder.</p>
<ul>
<li>CUB200:</li>
</ul>
<div class="codehilite"><pre><span></span><code>python run.py --reproduce_results &lt;experiment_to_reproduce&gt; <span class="se">\</span>
--experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--split_manager~SWAP~1 <span class="o">{</span>MLRCSplitManager: <span class="o">{}}</span> <span class="se">\</span>
--merge_argparse_when_resuming
</code></pre></div>


<ul>
<li>Cars196:</li>
</ul>
<div class="codehilite"><pre><span></span><code>python run.py --reproduce_results &lt;experiment_to_reproduce&gt; <span class="se">\</span>
--experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--config_dataset <span class="o">[</span>default, with_cars196<span class="o">]</span> <span class="se">\</span>
--config_general <span class="o">[</span>default, with_cars196<span class="o">]</span> <span class="se">\</span>
--split_manager~SWAP~1 <span class="o">{</span>MLRCSplitManager: <span class="o">{}}</span> <span class="se">\</span>
--merge_argparse_when_resuming
</code></pre></div>


<ul>
<li>Stanford Online Products</li>
</ul>
<div class="codehilite"><pre><span></span><code>python run.py --reproduce_results &lt;experiment_to_reproduce&gt; <span class="se">\</span>
--experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--config_dataset <span class="o">[</span>default, with_sop<span class="o">]</span> <span class="se">\</span>
--config_general <span class="o">[</span>default, with_sop<span class="o">]</span> <span class="se">\</span>
--split_manager~SWAP~1 <span class="o">{</span>MLRCSplitManager: <span class="o">{}}</span> <span class="se">\</span>
--merge_argparse_when_resuming
</code></pre></div>


<ul>
<li>CUB200 with batch size 256:</li>
</ul>
<div class="codehilite"><pre><span></span><code>python run.py --reproduce_results &lt;experiment_to_reproduce&gt; <span class="se">\</span>
--experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--config_general <span class="o">[</span>default, with_256_batch<span class="o">]</span> <span class="se">\</span>
--split_manager~SWAP~1 <span class="o">{</span>MLRCSplitManager: <span class="o">{}}</span> <span class="se">\</span>
--merge_argparse_when_resuming
</code></pre></div>


<p>If you don't have the datasets and would like to download them into your <code>dataset_root</code> folder, you can add this flag to the CUB commands:</p>
<div class="codehilite"><pre><span></span><code>--dataset~OVERRIDE~ <span class="o">{</span>CUB200: <span class="o">{</span>download: True<span class="o">}}</span>
</code></pre></div>


<p>Likewise, for the Cars196 and Stanford Online Products commands, replace the <code>--config_dataset</code> flag with:</p>
<div class="codehilite"><pre><span></span><code>--dataset~OVERRIDE~ <span class="o">{</span>Cars196: <span class="o">{</span>download: True<span class="o">}}</span>
</code></pre></div>


<p>or </p>
<div class="codehilite"><pre><span></span><code>--dataset~OVERRIDE~ <span class="o">{</span>StanfordOnlineProducts: <span class="o">{</span>download: True<span class="o">}}</span>
</code></pre></div>


<h3 id="run-evaluation-on-the-test-set">Run evaluation on the test set<a class="headerlink" href="#run-evaluation-on-the-test-set" title="Permanent link">&para;</a></h3>
<p>After training is done, you can get the "separate 128-dim" test set performance:</p>
<div class="codehilite"><pre><span></span><code>python run.py --experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--evaluate --splits_to_eval <span class="o">[</span>test<span class="o">]</span>
</code></pre></div>


<p>and the "concatenated 512-dim" test set performance:</p>
<div class="codehilite"><pre><span></span><code>python run.py --experiment_name &lt;your_experiment_name&gt; <span class="se">\</span>
--evaluate_ensemble --splits_to_eval <span class="o">[</span>test<span class="o">]</span>
</code></pre></div>


<p>Once evaluation is done, you can go to the <code>meta_logs</code> folder and view the results.</p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../../code/utils/" title="Utils" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Utils
              </div>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.92ffa368.min.js"></script>
      <script src="../../assets/javascripts/bundle.5123e3d4.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.a68abb33.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>